# Speaker Recognition System

A comprehensive speaker recognition system with web-based UI for audio annotation, speaker enrollment, and data management.

## üöÄ Quick Start

### Prerequisites
- Docker and Docker Compose
- Hugging Face account (for model access)
- 8GB+ RAM, 10GB+ disk space

### 1. Set up your Hugging Face token
```bash
export HF_TOKEN="your_huggingface_token"
```
Get your token from https://huggingface.co/settings/tokens

### 2. Start the system
```bash
cd extras/speaker-recognition
docker-compose up --build -d
```

This starts two services:
- **FastAPI backend** on http://localhost:8001 (speaker recognition API)
- **Streamlit web UI** on http://localhost:8501 (main interface)

### 3. Access the Web UI
Open http://localhost:8501 in your browser

### 4. Get Started
1. **Create a user** using the sidebar
2. **Upload audio** in the "Audio Viewer" page
3. **Annotate segments** in the "Annotation" page
4. **Enroll speakers** in the "Enrollment" page
5. **Manage & export** data in the "Speakers" page

## üéØ What You Can Do

- **üìÅ Upload & Visualize**: Interactive waveforms, spectrograms, segment selection
- **üìù Annotate Audio**: Label speaker segments, handle unknown speakers
- **üë§ Enroll Speakers**: Register speakers with quality assessment
- **üë• Manage Speakers**: View statistics, compare quality, bulk operations
- **üì§ Export Data**: Download audio in organized folders or concatenated files
- **üìä Analytics**: Track quality trends and system usage

## üõ†Ô∏è System Architecture

- **Multi-user Support**: Each user manages their own speaker data
- **SQLite Database**: Local storage for annotations, speakers, and sessions  
- **Quality Assessment**: Automatic audio quality scoring with recommendations
- **Export Formats**: 
  - Concatenated audio (max 10min per file)
  - Segmented files: `./exported_data/speaker-1/audio001.wav`
  - Metadata and annotations as JSON

## üìñ Deepgram Terminology in Speaker Recognition Context

When importing Deepgram transcripts, you'll encounter different data structures:

### Words
- **What**: Individual word-level transcription data with precise timestamps
- **Use**: Most accurate for speaker boundaries and timing
- **Example**: `{"word": "hello", "start": 1.23, "end": 1.45, "speaker": 0}`

### Segments  
- **What**: Groups of consecutive words from the same speaker
- **Use**: Natural speech chunks for annotation and training
- **Generated by**: DeepgramParser groups words by speaker changes
- **Example**: Speaker 1 talks from 0-5s, then Speaker 2 from 5-10s

### Paragraphs/Sentences
- **What**: Deepgram's paragraph-level grouping based on pauses/context
- **Use**: Better for readability but less precise for speaker boundaries
- **Note**: May combine multiple speakers if they talk quickly
- **Example**: A paragraph might span 30-60 seconds with multiple speakers

### Best Practice
The speaker recognition system uses **word-level data** to create segments because:
- Exact speaker change points (critical for training)
- No overlapping speakers in a segment
- Accurate timing for audio extraction

When you see mismatched text in the UI, it's often because:
- Old imports used paragraph-level data
- Display shows cached/different parsing method
- Solution: Re-import using current word-level parser

## üìö Documentation

For detailed documentation, API reference, and advanced usage:
- **[README.detailed.md](README.detailed.md)** - Comprehensive guide
- **[plan.md](plan.md)** - Implementation details

## üîß Configuration

Environment variables:
```bash
HF_TOKEN="your_token"                    # Required: Hugging Face token
SIMILARITY_THRESHOLD="0.85"              # Speaker similarity threshold (0.0-1.0)

# Speaker Service Configuration
SPEAKER_SERVICE_HOST="0.0.0.0"          # Speaker service bind host
SPEAKER_SERVICE_PORT="8085"             # Speaker service port
SPEAKER_SERVICE_URL="http://speaker-service:8085"  # URL for internal Docker communication

# Streamlit Web UI Configuration  
STREAMLIT_HOST="0.0.0.0"               # Web UI bind host
STREAMLIT_PORT="8502"                   # Web UI port
```

Copy `.env.template` to `.env` and configure your settings:
```bash
cp .env.template .env
# Edit .env with your configuration
```

## üö® Troubleshooting

**Can't access the web UI?**
- Check if services are running: `docker-compose ps`
- View logs: `docker-compose logs web-ui`

**Speaker service not responding?**
- Check backend logs: `docker-compose logs speaker-service`
- Verify HF_TOKEN is set correctly

**Models not downloading?**
- Ensure HF_TOKEN has access to PyAnnote models
- Check network connection and disk space

## üîÑ Development

For local development without Docker:
```bash
# Terminal 1 - Backend
uv sync
uv run python speaker_service.py

# Terminal 2 - Web UI  
uv run streamlit run web_ui.py
```

## API Endpoints

### Health Check
```bash
GET /health
```

### Speaker Enrollment
```bash
POST /enroll
Content-Type: application/json

{
  "speaker_id": "john_doe",
  "speaker_name": "John Doe", 
  "audio_file_path": "/path/to/audio.wav",
  "start_time": 0.0,  // optional
  "end_time": 5.0     // optional
}
```

### Speaker Identification
```bash
POST /identify
Content-Type: application/json

{
  "audio_file_path": "/path/to/audio.wav",
  "start_time": 0.0,  // optional
  "end_time": 5.0     // optional
}
```

### Speaker Diarization
```bash
POST /diarize
Content-Type: application/json

{
  "audio_file_path": "/path/to/audio.wav"
}
```

### List Speakers
```bash
GET /speakers
```

### Remove Speaker
```bash
DELETE /speakers/{speaker_id}
```

## Integration with Advanced Backend

The advanced backend communicates with this service through the `client.py` module, which provides both async and sync interfaces for backward compatibility.

## Laptop Client

The `laptop_client.py` provides a command-line interface for recording from your microphone and interacting with the speaker recognition service.

### Setup

1. **Install dependencies**:
   ```bash
   pip install -r requirements-laptop.txt
   ```

2. **Start the speaker service** (using Docker or locally):
   ```bash
   docker-compose up
   # or
   python speaker_service.py
   ```

### Usage

#### Enroll a Speaker
Record 10 seconds of audio to enroll a new speaker:
```bash
python laptop_client.py enroll --speaker-id "john" --speaker-name "John Doe" --duration 10
```

#### Identify a Speaker
Record 5 seconds of audio to identify who is speaking:
```bash
python laptop_client.py identify --duration 5
```

#### Verify a Speaker
Check if the voice matches a specific enrolled speaker:
```bash
python laptop_client.py verify --speaker-id "john" --duration 3
```

#### List Enrolled Speakers
```bash
python laptop_client.py list
```

#### Remove a Speaker
```bash
python laptop_client.py remove --speaker-id "john"
```

### Options

- `--service-url`: Change the service URL (default: http://localhost:8001)
- `--duration`: Recording duration in seconds
- `--speaker-id`: Unique identifier for speaker
- `--speaker-name`: Display name for speaker

### Example Workflow

1. Start the service:
   ```bash
   docker-compose up
   ```

2. Enroll yourself:
   ```bash
   python laptop_client.py enroll --speaker-id "myself" --speaker-name "My Name" --duration 15
   ```

3. Test identification:
   ```bash
   python laptop_client.py identify --duration 5
   ```

## Laptop Client

A command-line client (`laptop_client.py`) that can record from your microphone and interact with the speaker recognition service.

### Setup for Laptop Client

The laptop client requires PyAudio for microphone access:

```bash
# On Ubuntu/Debian
sudo apt-get install portaudio19-dev python3-pyaudio

# On macOS
brew install portaudio
pip install pyaudio

# On Windows
pip install pyaudio
```

### Usage Examples

```bash
# Start the speaker service first
docker-compose up -d

# Enroll a new speaker (records 10 seconds)
python laptop_client.py enroll --speaker-id "john" --speaker-name "John Doe" --duration 10

# Identify a speaker (records 5 seconds)
python laptop_client.py identify --duration 5

# Verify against a specific speaker (records 3 seconds)
python laptop_client.py verify --speaker-id "john" --duration 3

# List all enrolled speakers
python laptop_client.py list

# Remove a speaker
python laptop_client.py remove --speaker-id "john"

# Use different service URL
python laptop_client.py --service-url "http://192.168.1.100:8001" identify
```

### Laptop Client Features

- **Live Microphone Recording**: Records directly from your system microphone
- **Automatic Cleanup**: Temporary audio files are automatically cleaned up
- **Service Health Checks**: Verifies the speaker service is online before operations
- **Real-time Feedback**: Shows recording progress and results with emojis
- **Error Handling**: Graceful handling of network and audio errors

## Integration with Advanced Backend

The advanced backend communicates with this service through the `client.py` module, which provides both async and sync interfaces for backward compatibility.

## Performance Notes

- First inference may be slow due to model loading
- GPU memory usage scales with model size (~2-4GB)
- Audio files should be accessible from both services (use shared volumes)
- Microphone recording uses 16kHz sample rate for optimal compatibility
- Microphone recording requires `pyaudio` and proper audio device setup 