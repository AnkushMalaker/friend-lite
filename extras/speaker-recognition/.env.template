# Speaker Recognition Service Environment Configuration
# Copy this file to .env and fill in your values
#
# After copying, choose your deployment mode:
#   uv sync --group cpu    (CPU-only, lighter, works everywhere)
#   uv sync --group gpu    (GPU acceleration, requires NVIDIA+CUDA)

# Required: Hugging Face token for pyannote models
HF_TOKEN=your_huggingface_token_here

# Docker build configuration
# Choose 'cpu' for CPU-only deployment or 'gpu' for GPU acceleration
# This controls which dependency group is installed in the Docker image
COMPUTE_MODE=cpu

# PyTorch CUDA version (only used when COMPUTE_MODE=gpu)
# Options: cu121 (CUDA 12.1), cu126 (CUDA 12.6), cu128 (CUDA 12.8)
# Should match your system's CUDA version (check with: nvidia-smi)
PYTORCH_CUDA_VERSION=cu126

# Speaker recognition similarity threshold (0.0-1.0)
# Lower values = less strict identification, higher values = more strict
# Typical range: 0.1-0.3 for ECAPA-TDNN models
SIMILARITY_THRESHOLD=0.15

# Service Configuration
# SPEAKER_SERVICE_HOST: Interface to bind to (0.0.0.0 = all interfaces, allows cross-network access)
SPEAKER_SERVICE_HOST=0.0.0.0
SPEAKER_SERVICE_PORT=8085
SPEAKER_SERVICE_URL=http://speaker-service:8085

# React Web UI Configuration
REACT_UI_HOST=0.0.0.0
# Port configuration (recommended defaults):
#   HTTP mode: 5174 (direct access, localhost microphone only)
#   HTTPS mode: 5175 (internal, proxied via nginx on 8444/8081)
REACT_UI_PORT=5174
REACT_UI_HTTPS=false

# Optional: External Services
DEEPGRAM_API_KEY=your_deepgram_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# Test Configuration (for docker-compose-test.yml)
SPEAKER_SERVICE_TEST_PORT=8086