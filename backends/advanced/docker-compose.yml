services:
  friend-backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env
    volumes:
      - ./src:/app/src  # Mount source code for development
      - ./data/audio_chunks:/app/audio_chunks
      - ./data/debug_dir:/app/debug_dir
      - ./data:/app/data
    environment:
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - MISTRAL_MODEL=${MISTRAL_MODEL}
      - TRANSCRIPTION_PROVIDER=${TRANSCRIPTION_PROVIDER}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - SPEAKER_SERVICE_URL=${SPEAKER_SERVICE_URL}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - ADMIN_EMAIL=${ADMIN_EMAIL}
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL}
      - OPENAI_MODEL=${OPENAI_MODEL}
      - NEO4J_HOST=${NEO4J_HOST}
      - NEO4J_USER=${NEO4J_USER}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      - LANGFUSE_ENABLE_TELEMETRY=${LANGFUSE_ENABLE_TELEMETRY}
      # OpenMemory MCP configuration
      - MEMORY_PROVIDER=${MEMORY_PROVIDER}
      - OPENMEMORY_MCP_URL=${OPENMEMORY_MCP_URL:-http://host.docker.internal:8765}
      - OPENMEMORY_CLIENT_NAME=${OPENMEMORY_CLIENT_NAME:-friend_lite}
      - OPENMEMORY_USER_ID=${OPENMEMORY_USER_ID:-openmemory}
      - OPENMEMORY_TIMEOUT=${OPENMEMORY_TIMEOUT:-30}
    depends_on:
      # You may not want qdrant if you are using openmemory_mcp
      # qdrant:
      #   condition: service_started
      mongo:
        condition: service_started
      # neo4j-mem0:
      #   condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/readiness"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 5s
    restart: unless-stopped

  # Development webui service (default)
  webui:
    build:
      context: ./webui
      dockerfile: Dockerfile.dev
    ports:
      - "${WEBUI_PORT:-5173}:5173"
    environment:
      # Don't set VITE_BACKEND_URL - let frontend auto-detect based on access method
      # - VITE_BACKEND_URL=http://${HOST_IP}:${BACKEND_PUBLIC_PORT:-8000}
      - VITE_HMR_PORT=443
    volumes:
      - ./webui/src:/app/src
      - ./webui/public:/app/public
    depends_on:
      friend-backend:
        condition: service_healthy
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333" # gRPC
      - "6334:6334" # HTTP
    volumes:
      - ./data/qdrant_data:/qdrant/storage 
  

  mongo:
    image: mongo:4.4.18
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongo_data:/data/db

  # OpenMemory MCP Server - Use external server from extras/openmemory-mcp
  # The Friend-Lite backend connects to the external OpenMemory MCP server
  # running from extras/openmemory-mcp via host.docker.internal:8765
  # 
  # To start the external server:
  # cd extras/openmemory-mcp && docker compose up -d

  # Nginx reverse proxy for HTTPS access
  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      friend-backend:
        condition: service_healthy
      webui:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "-k", "https://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  ##  Additional

  # neo4j-mem0:
  #   image: neo4j:5.15-community
  #   ports:
  #     - "7474:7474" # HTTP
  #     - "7687:7687" # Bolt
  #   environment:
  #     - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-password}
  #     - NEO4J_PLUGINS=["apoc"]
  #     - NEO4J_dbms_security_procedures_unrestricted=apoc.*
  #     - NEO4J_dbms_security_procedures_allowlist=apoc.*
  #   volumes:
  #     - ./data/neo4j_data:/data
  #     - ./data/neo4j_logs:/logs
  #   restart: unless-stopped

  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]





# Question: These are named volumes, but they are not being used, right? Can we remove them?
# volumes:
#   ollama_data:
#     driver: local
#   mongo_data:
#     driver: local
#   neo4j_data:
#     driver: local
#   neo4j_logs:
#     driver: local
