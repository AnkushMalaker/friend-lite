services:
  friend-backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./audio_chunks:/app/audio_chunks
      - ./debug_dir:/app/debug_dir
    environment:
      - DEEPGRAM_API_KEY=${DEEPGRAM_API_KEY}
      - OFFLINE_ASR_TCP_URI=${OFFLINE_ASR_TCP_URI}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - HF_TOKEN=${HF_TOKEN}
      - SPEAKER_SERVICE_URL=${SPEAKER_SERVICE_URL}
      - ADMIN_USERNAME=${ADMIN_USERNAME}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD}
      - ADMIN_EMAIL=${ADMIN_EMAIL}
      - COOKIE_SECURE=${COOKIE_SECURE}
      - AUTH_SECRET_KEY=${AUTH_SECRET_KEY}
    depends_on:
      qdrant:
        condition: service_started
      mongo:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/readiness"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    restart: unless-stopped

  streamlit:
    build:
      context: ./webui
      dockerfile: Dockerfile
    ports:
      - "8501:8501"
    environment:
      - BACKEND_API_URL=http://friend-backend:8000
      - BACKEND_PUBLIC_URL=http://localhost:8000
    depends_on:
      friend-backend:
        condition: service_healthy
      mongo:
        condition: service_started
      qdrant:
        condition: service_started
    volumes:
      - ./webui:/app

  proxy:
    image: nginx:alpine
    depends_on: [friend-backend, streamlit]
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    ports: ["80:80"]          # publish once; ngrok points here

  # speaker-recognition:
  #   build:
  #     context: ../../extras/speaker-recognition
  #     dockerfile: Dockerfile
  #   # image: speaker-recognition:latest
  #   ports:
  #     - "8001:8001"
  #   volumes:
  #     # Persist Hugging Face cache (models) between restarts
  #     - ./speaker_model_cache:/models
  #     - ./audio_chunks:/app/audio_chunks  # Share audio chunks with backend
  #     - ./speaker_debug:/app/debug
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  #   environment:
  #     - HF_HOME=/models
  #     - HF_TOKEN=${HF_TOKEN}
  #     - SIMILARITY_THRESHOLD=0.85
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
    
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]


  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333" # gRPC
      - "6334:6334" # HTTP
    volumes:
      - ./qdrant_data:/qdrant/storage 
  mongo:
    image: mongo:4.4.18
    ports:
      - "27017:27017"
    volumes:
      - ./mongo_data:/data/db

  # UNCOMMENT OUT FOR LOCAL DEMO - EXPOSES to internet
  # ngrok:
  #   image: ngrok/ngrok:latest
  #   depends_on: [friend-backend, proxy]
  #   ports:
  #     - "4040:4040" # Ngrok web interface
  #   environment:
  #     - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
  #   command: "http proxy:80 --url=${NGROK_URL} --basic-auth=${NGROK_BASIC_AUTH}"


# Question: These are named volumes, but they are not being used, right? Can we remove them?
volumes:
  ollama_data:
    driver: local
  mongo_data:
    driver: local