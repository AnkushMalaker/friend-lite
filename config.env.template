# ========================================
# Friend-Lite Environment Configuration
# ========================================
# This file contains all environment variable definitions
# Add new variables here - they will be automatically included in all generated configs

# ========================================
# DEPLOYMENT SETTINGS
# ========================================

# Infrastructure namespaces
INFRASTRUCTURE_NAMESPACE = root
APPLICATION_NAMESPACE = friend-lite

# Deployment mode: docker-compose, kubernetes, or distributed
DEPLOYMENT_MODE = kubernetes

# Container registry (for kubernetes/skaffold)
CONTAINER_REGISTRY = anubis:32000

# ========================================
# NETWORK CONFIGURATION
# ========================================

# Primary domain/IP for all services
DOMAIN = 192-168-1-140.nip.io
DOMAIN_PREFIX = friend-lite
EXTERNAL_DOMAIN = omi-lite.qualitai.co.uk

# Service ports (Docker Compose mode)
BACKEND_PORT = 8000
WEBUI_PORT = 5173
SPEAKER_PORT = 8085
MONGODB_PORT = 27017
QDRANT_PORT = 6333
NGROK_PORT = 4040

# Kubernetes node ports (for LoadBalancer services)
BACKEND_NODEPORT = 30270
WEBUI_NODEPORT = 31011
SPEAKER_NODEPORT = 30285

# ========================================
# AUTHENTICATION & SECURITY
# ========================================

# JWT secret key - make this random and long
AUTH_SECRET_KEY = demo-secret-key-please-change-in-production-make-it-random-and-long

# Admin account
ADMIN_EMAIL = admin@example.com
ADMIN_PASSWORD = ******

# ========================================
# LLM CONFIGURATION
# ========================================

# LLM Provider: openai, ollama, or groq
LLM_PROVIDER = openai

# OpenAI configuration
OPENAI_API_KEY = sk-xxxxx
OPENAI_BASE_URL = https://api.openai.com/v1
OPENAI_MODEL = gpt-4o-mini

# Ollama configuration (when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL = http://ollama:11434
OLLAMA_MODEL = llama3.1:latest

# Chat-specific settings
CHAT_TEMPERATURE = 0.7

# ========================================
# SPEECH-TO-TEXT CONFIGURATION
# ========================================

# Primary transcription provider: deepgram, mistral, or parakeet
TRANSCRIPTION_PROVIDER = deepgram

# Deepgram configuration
DEEPGRAM_API_KEY = 90xxxxxx

# Mistral configuration (when TRANSCRIPTION_PROVIDER=mistral)
MISTRAL_API_KEY = 
MISTRAL_MODEL = voxtral-mini-2507

# Parakeet ASR configuration (when TRANSCRIPTION_PROVIDER=parakeet)
PARAKEET_ASR_URL = http://host.docker.internal:8767

# ========================================
# DATABASE CONFIGURATION
# ========================================

# MongoDB URIs
MONGODB_URI = mongodb://mongo:$(MONGODB_PORT)
MONGODB_K8S_URI = mongodb://mongodb.$(INFRASTRUCTURE_NAMESPACE).svc.cluster.local:27017/friend

# Qdrant URLs
QDRANT_BASE_URL = qdrant
QDRANT_K8S_URL = qdrant.$(INFRASTRUCTURE_NAMESPACE).svc.cluster.local

# Neo4j configuration (optional)
NEO4J_HOST = neo4j.root.local.svc.cluster.local
NEO4J_USER = neo4j
NEO4J_PASSWORD = neo4jpass

# ========================================
# MEMORY PROVIDER CONFIGURATION
# ========================================

# Memory Provider: friend_lite or openmemory_mcp
MEMORY_PROVIDER = openmemory_mcp

# OpenMemory MCP configuration (when MEMORY_PROVIDER=openmemory_mcp)
OPENMEMORY_MCP_URL = http://mem0-api.svc.cluster.local:8765
OPENMEMORY_CLIENT_NAME = friend_lite
OPENMEMORY_USER_ID = user
OPENMEMORY_TIMEOUT = 30

# ========================================
# SPEAKER RECOGNITION CONFIGURATION
# ========================================

# Hugging Face token for speaker recognition models
HF_TOKEN = hf_xxxxx

# Speaker recognition settings
SIMILARITY_THRESHOLD = 0.15
COMPUTE_MODE = gpu

# Node deployment configuration
SPEAKER_NODE = xxxxx

# React UI settings for speaker recognition
REACT_UI_HOST = 0.0.0.0
REACT_UI_PORT = 5173
REACT_UI_HTTPS = false

# ========================================
# COMPUTED VALUES
# ========================================

# Host configurations
BACKEND_HOST = $(DOMAIN_PREFIX).$(DOMAIN)
WEBUI_HOST = $(DOMAIN_PREFIX).$(DOMAIN)
SPEAKER_HOST = speaker.$(DOMAIN)

# Service URLs
BACKEND_URL = http://$(DOMAIN_PREFIX).$(DOMAIN):$(BACKEND_PORT)
WEBUI_URL = http://$(DOMAIN_PREFIX).$(DOMAIN):$(WEBUI_PORT)
SPEAKER_SERVICE_URL = http://speaker-recognition-speaker.speech.svc.cluster.local:$(SPEAKER_PORT)

# CORS and Vite configuration
CORS_ORIGINS = http://$(DOMAIN):$(WEBUI_PORT),http://$(DOMAIN):3000,http://localhost:$(WEBUI_PORT),http://localhost:3000
VITE_ALLOWED_HOSTS = localhost 127.0.0.1 $(DOMAIN_PREFIX).$(DOMAIN) $(EXTERNAL_DOMAIN) $(SPEAKER_HOST)

# Model configuration
CHAT_LLM_MODEL = $(OPENAI_MODEL)

# ========================================
# OPTIONAL SERVICES
# ========================================

# Groq API (alternative LLM provider)
GROQ_API_KEY = 

# Langfuse telemetry
LANGFUSE_PUBLIC_KEY = 
LANGFUSE_SECRET_KEY = 
LANGFUSE_HOST = http://x.x.x.x:3002
LANGFUSE_ENABLE_TELEMETRY = false

# Ngrok for external access
NGROK_AUTHTOKEN = 

# ========================================
# AUDIO PROCESSING SETTINGS
# ========================================

NEW_CONVERSATION_TIMEOUT_MINUTES = 1.5
AUDIO_CROPPING_ENABLED = true
MIN_SPEECH_SEGMENT_DURATION = 1.0
CROPPING_CONTEXT_PADDING = 0.1

# ========================================
# DEVELOPMENT & DEBUG SETTINGS
# ========================================

# Environment
ENVIRONMENT = dev
NODE_ENV = production

# Debug settings
DEBUG_DIR = ./data/debug_dir
MEM0_TELEMETRY = false

# Storage settings
PERSISTENCE_SIZE = 10Gi
STORAGE_CLASS = openebs-hostpath

# ========================================
# KUBERNETES-SPECIFIC SETTINGS
# ========================================

# Image pull policy
IMAGE_PULL_POLICY = Always

# Resource limits
BACKEND_CPU_LIMIT = 1000m
BACKEND_MEMORY_LIMIT = 2Gi
BACKEND_CPU_REQUEST = 200m
BACKEND_MEMORY_REQUEST = 1Gi

WEBUI_CPU_LIMIT = 500m
WEBUI_MEMORY_LIMIT = 512Mi
WEBUI_CPU_REQUEST = 100m
WEBUI_MEMORY_REQUEST = 128Mi

SPEAKER_CPU_LIMIT = 2000m
SPEAKER_MEMORY_LIMIT = 4Gi
SPEAKER_CPU_REQUEST = 500m
SPEAKER_MEMORY_REQUEST = 2Gi

# ========================================
# ADD NEW ENVIRONMENT VARIABLES HERE
# ========================================
# 
# To add a new environment variable:
# 1. Add it to this file (either as a default value with ?= or computed with =)
# 2. That's it! It will be automatically available in all generated configs
#
# Examples:
# NEW_SERVICE_URL = http://$(DOMAIN):$(NEW_SERVICE_PORT)
# NEW_SERVICE_PORT ?= 9000
# NEW_FEATURE_ENABLED ?= true
