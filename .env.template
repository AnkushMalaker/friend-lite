# ========================================
# FRIEND-LITE MASTER CONFIGURATION
# ========================================
# This is the master configuration template for the entire Friend-Lite project.
# Copy this file to .env and customize values, then run 'make config' to generate
# all service-specific configuration files.

# ========================================
# DEPLOYMENT SETTINGS
# ========================================

# Infrastructure namespaces
INFRASTRUCTURE_NAMESPACE=infrastructure
APPLICATION_NAMESPACE=friend-lite

# Deployment mode: docker-compose, kubernetes, or distributed
DEPLOYMENT_MODE=docker-compose

# Container registry (for kubernetes/skaffold)
CONTAINER_REGISTRY=localhost:32000

# ========================================
# NETWORK CONFIGURATION
# ========================================

# Primary domain/IP for all services
# Examples: localhost, 192.168.1.100, friend-lite.example.com, 100.x.x.x (Tailscale)
DOMAIN=localhost

# Service ports (Docker Compose mode)
BACKEND_PORT=8000
WEBUI_PORT=5173
SPEAKER_PORT=8085
MONGODB_PORT=27017
QDRANT_PORT=6333
NGROK_PORT=4040

# Kubernetes node ports (for LoadBalancer services)
BACKEND_NODEPORT=30270
WEBUI_NODEPORT=31011
SPEAKER_NODEPORT=30285

# Generated service URLs (computed from above)
BACKEND_HOST=${DOMAIN}
WEBUI_HOST=${DOMAIN}
SPEAKER_HOST=speaker.${DOMAIN}
BACKEND_URL=http://${DOMAIN}:${BACKEND_PORT}
WEBUI_URL=http://${DOMAIN}:${WEBUI_PORT}
SPEAKER_SERVICE_URL=http://${DOMAIN}:${SPEAKER_PORT}

# ========================================
# AUTHENTICATION & SECURITY
# ========================================

# JWT secret key - make this random and long
AUTH_SECRET_KEY=your-super-secret-jwt-key-here-make-it-random-and-long

# Admin account
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=secure-admin-password

# CORS origins (auto-generated based on DOMAIN and ports)
CORS_ORIGINS=http://${DOMAIN}:${WEBUI_PORT},http://${DOMAIN}:3000,http://localhost:${WEBUI_PORT},http://localhost:3000

# ========================================
# LLM CONFIGURATION
# ========================================

# LLM Provider: openai, ollama, or groq
LLM_PROVIDER=openai

# OpenAI configuration
OPENAI_API_KEY=your-openai-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# Ollama configuration (when LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3.1:latest

# Chat-specific settings
CHAT_LLM_MODEL=${OPENAI_MODEL}
CHAT_TEMPERATURE=0.7

# ========================================
# SPEECH-TO-TEXT CONFIGURATION
# ========================================

# Primary transcription provider: deepgram, mistral, or parakeet
TRANSCRIPTION_PROVIDER=deepgram

# Deepgram configuration
DEEPGRAM_API_KEY=your-deepgram-key-here

# Mistral configuration (when TRANSCRIPTION_PROVIDER=mistral)
MISTRAL_API_KEY=your-mistral-key-here
MISTRAL_MODEL=voxtral-mini-2507

# Parakeet ASR configuration (when TRANSCRIPTION_PROVIDER=parakeet)
PARAKEET_ASR_URL=http://host.docker.internal:8767

# ========================================
# DATABASE CONFIGURATION
# ========================================

# MongoDB configuration
MONGODB_URI=mongodb://mongo:${MONGODB_PORT}
MONGODB_K8S_URI=mongodb://mongodb.${INFRASTRUCTURE_NAMESPACE}.svc.cluster.local:27017/friend-lite

# Qdrant configuration
QDRANT_BASE_URL=qdrant
QDRANT_K8S_URL=qdrant.${INFRASTRUCTURE_NAMESPACE}.svc.cluster.local

# Neo4j configuration (optional)
NEO4J_HOST=neo4j-mem0
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j-password

# ========================================
# MEMORY PROVIDER CONFIGURATION
# ========================================

# Memory Provider: friend_lite or openmemory_mcp
MEMORY_PROVIDER=friend_lite

# OpenMemory MCP configuration (when MEMORY_PROVIDER=openmemory_mcp)
OPENMEMORY_MCP_URL=http://host.docker.internal:8765
OPENMEMORY_CLIENT_NAME=friend_lite
OPENMEMORY_USER_ID=openmemory
OPENMEMORY_TIMEOUT=30

# ========================================
# SPEAKER RECOGNITION CONFIGURATION
# ========================================

# Hugging Face token for speaker recognition models
HF_TOKEN=your-huggingface-token-here

# Speaker recognition settings
SIMILARITY_THRESHOLD=0.15
COMPUTE_MODE=cpu

# Speaker service configuration
SPEAKER_SERVICE_HOST=speaker-service
SPEAKER_SERVICE_PORT=${SPEAKER_PORT}

# React UI settings for speaker recognition
REACT_UI_HOST=0.0.0.0
REACT_UI_PORT=5174
REACT_UI_HTTPS=false
WEBUI_CORS_ORIGIN=*

# Vite configuration
VITE_ALLOWED_HOSTS=localhost 127.0.0.1 ${DOMAIN}
# ========================================
# OPTIONAL SERVICES
# ========================================

# Groq API (alternative LLM provider)
GROQ_API_KEY=your-groq-api-key-here

# Langfuse telemetry
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=http://x.x.x.x:3002
LANGFUSE_ENABLE_TELEMETRY=false

# Ngrok for external access
NGROK_AUTHTOKEN=your-ngrok-token-here

# ========================================
# AUDIO PROCESSING SETTINGS
# ========================================

NEW_CONVERSATION_TIMEOUT_MINUTES=1.5
AUDIO_CROPPING_ENABLED=true
MIN_SPEECH_SEGMENT_DURATION=1.0
CROPPING_CONTEXT_PADDING=0.1

# ========================================
# DEVELOPMENT & DEBUG SETTINGS
# ========================================

# Environment
ENVIRONMENT=dev
NODE_ENV=production

# Debug settings
DEBUG_DIR=./data/debug_dir
MEM0_TELEMETRY=false

# Host IP for public access (Docker host IP)
HOST_IP=${DOMAIN}
BACKEND_PUBLIC_PORT=${BACKEND_PORT}

# Storage settings
PERSISTENCE_SIZE=10Gi
STORAGE_CLASS=openebs-hostpath

# ========================================
# KUBERNETES-SPECIFIC SETTINGS
# ========================================

# Image pull policy
IMAGE_PULL_POLICY=Always

# Resource limits
BACKEND_CPU_LIMIT=1000m
BACKEND_MEMORY_LIMIT=2Gi
BACKEND_CPU_REQUEST=200m
BACKEND_MEMORY_REQUEST=1Gi

WEBUI_CPU_LIMIT=500m
WEBUI_MEMORY_LIMIT=512Mi
WEBUI_CPU_REQUEST=100m
WEBUI_MEMORY_REQUEST=128Mi

SPEAKER_CPU_LIMIT=2000m
SPEAKER_MEMORY_LIMIT=4Gi
SPEAKER_CPU_REQUEST=500m
SPEAKER_MEMORY_REQUEST=2Gi